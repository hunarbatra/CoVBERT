{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OsLPwEgQw7QO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: ^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniforge/base/bin/huggingface-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 41, in main\n",
            "    service.run()\n",
            "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/huggingface_hub/commands/user.py\", line 142, in run\n",
            "    username = input(\"Username: \")\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWSmR1R_yxiv"
      },
      "outputs": [],
      "source": [
        "!pip3 install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JphPos-Xy0Y0"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubl90T47zlqP"
      },
      "outputs": [],
      "source": [
        "%env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9CGz69Wzh9"
      },
      "source": [
        "## Download Data (Pre-processed 230,623 spike glycoprotein sequences stored on github)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU7BL2usWOoP"
      },
      "outputs": [],
      "source": [
        "!wget https://media.githubusercontent.com/media/hunarbatra/covid-spike-data/master/spike-gisaid.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQfVuhv3XKhz"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anGz5iMHXpWU"
      },
      "source": [
        "## Tokenizer Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJZAoZHLXLA1"
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "import os\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "paths = [str(x) for x in Path(\"../transformer_data/\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=20, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])\n",
        "\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "print(vocab_size)\n",
        "print(tokenizer.get_vocab())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7luqviQHYQ8J"
      },
      "outputs": [],
      "source": [
        "!mkdir CoVBERT\n",
        "tokenizer.save_model(\"CoVBERT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWO7oAKJYoaW"
      },
      "outputs": [],
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./CoVBERT/vocab.json\",\n",
        "    \"./CoVBERT/merges.txt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DlJo_0iY9Ta"
      },
      "outputs": [],
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trGxunBvZX4W"
      },
      "outputs": [],
      "source": [
        "tokenizer.encode(\"MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHVIHVSGTNGTKR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLKRqwDIZlwB"
      },
      "outputs": [],
      "source": [
        "tokenizer.encode(\"MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHVIHVSGTNGTKR\").tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfOvFGIIZvxW"
      },
      "source": [
        "# CoVBERT training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcAgG4PiaO2t",
        "outputId": "0d14c231-2e25-461e-b8ca-00836a54af40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60v-DiAfegvw"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    max_position_embeddings=2048,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJw1ueF1ehC6"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./CoVBERT\", max_len=2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBI-DMa_gOSq"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4PL1dskiIRN",
        "outputId": "99613164-78ba-4909-f215-0a095b3f98a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44895237"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.num_parameters()\n",
        "# => 44 million parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehsnAgZEiN1c"
      },
      "source": [
        "Building the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73dLZr-HiJAp",
        "outputId": "2e113bbd-0b02-42c9-ba6e-a9d4101e0384"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 41s, sys: 33.6 s, total: 5min 14s\n",
            "Wall time: 55.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"./spike-gisaid.txt\",\n",
        "    block_size=1389,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TUi47S0jU-R"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WrNXuS8uI7k"
      },
      "outputs": [],
      "source": [
        "dataset = dataset[:50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMFzsEPHjjzS",
        "outputId": "eacdedd7-25dc-49f6-ee5a-4720eb9d2228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of training samples:  40001\n",
            "# of evaluation samples: 9999\n"
          ]
        }
      ],
      "source": [
        "# Split dataset X% train, (1-X)% test ----- > 85% train, 15% test\n",
        "X = 80\n",
        "train_csv = dataset[int((1-float(X)/100) * len(dataset)):]\n",
        "eval_csv = dataset[:int((1-float(X)/100) * len(dataset))]\n",
        "print(f\"# of training samples:  {len(train_csv)}\")\n",
        "print(f'# of evaluation samples: {len(eval_csv)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j3P5y6Kjloc",
        "outputId": "ffc703db-661a-4d28-c25e-8e0a20c441c3"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    report_to = 'wandb',  # enable logging to W&B\n",
        "    run_name = 'covbert_training', # name of the W&B run\n",
        "    output_dir=\"./CoVBERT\",\n",
        "    evaluation_strategy = 'steps', \n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8, # crashes with 16, ... 64...\n",
        "    # per_gpu_train_batch_size=64,\n",
        "    logging_steps = 100, # we will log every 100 steps\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_csv ,\n",
        "    eval_dataset=eval_csv,\n",
        "    # compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j7DuYBQkuqN"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gjXf7JsSkEjp",
        "outputId": "903080c6-211a-4c50-88de-67df479dab22"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrLdLQymq-KQ"
      },
      "source": [
        "Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEAJQyNCk3Uf"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd6P1k_brD5_"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRS7bRgurE7U"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./CoVBERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tbrrBAKv7-C"
      },
      "source": [
        "Push model to HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6bO-tiFvRP8"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqpeqehlytaP"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
